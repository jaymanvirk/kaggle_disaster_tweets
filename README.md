# Natural Language Processing with Disaster Tweets:  Assessing performance of the baseline LSTM and GRU models on different data samplings

## Abstract
This study evaluates the performance of two recurrent neural network (RNN) architectures, Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), in the text classification problem. The data is based on Disaster Tweets dataset (Addison Howard et al.,2019) and consists of tweets categorized into two classes: disastrous and non-disastrous. The analysis includes an examination of the LSTM and GRU baseline architectures efficiency and their response to various data sampling methods (original, upsampled, downsampled) to handle dataset imbalance.
